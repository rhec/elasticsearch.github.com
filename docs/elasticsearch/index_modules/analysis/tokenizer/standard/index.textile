---
layout: doc_es
title: ElasticSearch Docs | Index Modules | Analysis | Tokenizer | Standard
---

<script type="text/javascript">
docBreadcrumb = [
    ["elasticsearch", "ElasticSearch"], 
    ["index_modules", "Index Modules"], 
    ["analysis", "Analysis"], 
    ["tokenizer", "Tokenizer"], 
    ["standard", "Standard"], 
];
</script>

h1. Standard Tokenizer

p. A tokenizer of type @standard@ providing grammar based tokenizer that is a good tokenizer for most European language documents. It splits words at punctuation characters, removing punctuation. However, a  dot that's not followed by whitespace is considered part of a token. It also splits words at hyphens, unless there's a number in the token, in which case the whole token is interpreted as a product number and is not split. It recognizes email addresses and internet hostnames as one token.

p. The following are settings that can be set for a @standard@ tokenizer type:

|_. Setting |_. Description |
|@max_token_length@|The maximum token length. If a token is seen that exceeds this length then it is discarded. Defaults to @255@.|
